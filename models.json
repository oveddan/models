[
  {
    "containerId": "84d72a2f82f6",
    "available": true,
    "tag": "cvalenzuelab/im2text:latest",
    "name": "im2txt",
    "specs": {
      "cpu": true,
      "gpu": true
    },
    "port": "33100",
    "query": {
      "http": {
        "route": "query_once",
        "method": "post",
        "type": "JSON"
      },
      "socket": {
        "namespace": "query",
        "emit": "update_request",
        "event": "update_response"
      },
      "format": {
        "data": "data:image/jpg;base64,"
      }
    },
    "size": ["2.19", "GB"],
    "options": {
      "image": "84d72a2f82f6",
      "Tty": false,
      "Detach": true,
      "ExposedPorts": { "33000/tcp": {} },
      "HostConfig": {
        "AutoRemove": true,
        "PortBindings": {
          "33000/tcp": [{
            "HostIP": "0.0.0.0",
            "HostPort": "33100"
          }]
        }
      }
    },
    "needsTraining": false,
    "description": {
      "first": "The im2txt model, also called the Show and Tell model, is a deep neural network that learns how to describe the content of images",
      "second": "More technically, it is an example of an encoder-decoder neural network. It works by first 'encoding' an image into a fixed-length vector representation, and then 'decoding' the representation into a natural language description.",
      "third": "The image encoder is a deep convolutional neural network. This type of network is widely used for image tasks and is currently state-of-the-art for object recognition and detection. Our particular choice of network is the Inception v3 image recognition model pretrained on the ILSVRC-2012-CLS image classification dataset. The decoder is a long short-term memory (LSTM) network. This type of network is commonly used for sequence modeling tasks such as language modeling and machine translation. In the Show and Tell model, the LSTM network is trained as a language model conditioned on the image encoding.",
      "authors": "Oriol Vinyals, Alexander Toshev, Samy Bengio, Dumitru Erhan.",
      "image": "https://raw.githubusercontent.com/runwayml/models/master/im2txt/imgs/demo.png",
      "organization": "Google",
      "framework": "Tensorflow",
      "github": "https://github.com/tensorflow/models/tree/master/research/im2txt",
      "paper": "https://arxiv.org/abs/1609.06647",
      "licence": "Apache License 2.0"
    },
    "inputs": ["Image", "Video"]
  },
  {
    "containerId": "528c549ae8f8",
    "available": true,
    "tag": "cvalenzuelab/openpose:latest",
    "name": "OpenPose",
    "specs": {
      "cpu": false,
      "gpu": true
    },
    "port": "33200",
    "query": {
      "http": {
        "route": "test",
        "method": "get",
        "type": "JSON"
      },
      "socket": {
        "namespace": "query",
        "emit": "update_request",
        "event": "update_response"
      },
      "format": {
        "data": "data:image/jpg;base64,",
        "model": "mobilenet_thin"
      }
    },
    "size": ["2.69", "GB"],
    "options": {
      "image": "528c549ae8f8",
      "Tty": false,
      "Detach": true,
      "ExposedPorts": { "33000/tcp": {} },
      "HostConfig": {
        "AutoRemove": true,
        "PortBindings": {
          "33000/tcp": [{
            "HostIP": "0.0.0.0",
            "HostPort": "33200"
          }]
        }
      }
    },
    "needsTraining": false,
    "description": {
      "first": "Real-time multi-person keypoint detection library for body, face, and hands estimation.",
      "second": "OpenPose represents the first real-time multi-person system to jointly detect human body, hand, and facial keypoints (in total 130 keypoints) on single images.",
      "third": "Functionality include: real-time multi-person keypoint detection, 15 or 18-keypoint body estimation. Running time invariant to number of detected people, 2x21-keypoint hand estimation. Currently, running time depends on number of detected people, 70-keypoint face estimation. Currently, running time depends on number of detected people.",
      "authors": "Gines Hidalgo, Zhe Cao, Tomas Simon, Shih-En Wei, Hanbyul Joo, and Yaser Sheikh.",
      "image": "https://raw.githubusercontent.com/runwayml/models/master/openpose/images/demo.png",
      "organization": "CMU Perceptual Computing Lab",
      "framework": "Caffe2",
      "github": "https://github.com/CMU-Perceptual-Computing-Lab/openpose",
      "paper": "https://arxiv.org/abs/1611.08050",
      "licence": "Apache License 2.0"
    },
    "inputs": ["Image", "Video"]
  },
  {
    "containerId": "e1b0679331aa",
    "available": true,
    "tag": "cvalenzuelab/yolo:latest",
    "name": "YOLO",
    "specs": {
      "cpu": false,
      "gpu": true
    },
    "port": "33300",
    "query": {
      "http": {
        "route": "test",
        "method": "get",
        "type": "JSON"
      },
      "socket": {
        "namespace": "query",
        "emit": "update_request",
        "event": "update_response"
      },
      "format": {
        "data": "data:image/jpg;base64,"
      }
    },
    "size": ["5.69", "GB"],
    "options": {
      "image": "e1b0679331aa",
      "Tty": false,
      "Detach": true,
      "ExposedPorts": { "33000/tcp": {} },
      "HostConfig": {
        "AutoRemove": true,
        "PortBindings": {
          "33000/tcp": [{
            "HostIP": "0.0.0.0",
            "HostPort": "33300"
          }]
        }
      }
    },
    "needsTraining": false,
    "description": {
      "first": "You only look once (YOLO) is a state-of-the-art, real-time object detection system.",
      "second": "This model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image.",
      "third": "Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities.",
      "authors": "Redmon, Joseph and Farhadi, Ali",
      "image": "https://raw.githubusercontent.com/runwayml/models/master/yolo/images/demo.png",
      "organization": "Darknet",
      "framework": "Darknet",
      "github": "https://github.com/pjreddie/darknet",
      "paper": "https://arxiv.org/abs/1506.02640",
      "licence": "DO WHAT THE F**K YOU WANT TO PUBLIC LICENSE"
    },
    "inputs": ["Image", "Video"]
  },
  {
    "containerId": "2521b5010a8a",
    "available": true,
    "tag": "cvalenzuelab/gaze:latest",
    "name": "GazeCapture",
    "specs": {
      "cpu": true,
      "gpu": true
    },
    "port": "33400",
    "query": {
      "http": {
        "route": "test",
        "method": "get",
        "type": "JSON"
      },
      "socket": {
        "namespace": "query",
        "emit": "update_request",
        "event": "update_response"
      },
      "format": {
        "data": "data:image/jpg;base64,"
      }
    },
    "size": ["2.01", "GB"],
    "options": {
      "image": "2521b5010a8a",
      "Tty": false,
      "Detach": true,
      "ExposedPorts": { "33000/tcp": {} },
      "HostConfig": {
        "AutoRemove": true,
        "PortBindings": {
          "33000/tcp": [{
            "HostIP": "0.0.0.0",
            "HostPort": "33400"
          }]
        }
      }
    },
    "needsTraining": false,
    "description": {
      "first": "Eye tracking using the first large-scale dataset for eye tracking, containing data from over 1450 people consisting of almost 2.5M frames.",
      "second": "From scientific research to commercial applications, eye tracking is an important tool across many domains. Despite its range of applications, eye tracking has yet to become a pervasive technology. This model can put the power of eye tracking in everyone's palm by building eye tracking software that works on commodity hardware such as mobile phones and tablets, without the need for additional sensors or devices.",
      "third": "This model achieves a prediction error of 1.7cm and 2.5cm without calibration on mobile phones and tablets respectively. With calibration, this is reduced to 1.3cm and 2.1cm.",
      "authors": "Kyle Krafka and Aditya Khosla and Petr Kellnhofer and Harini Kannan and Suchendra Bhandarkar and Wojciech Matusik and Antonio Torralba",
      "image": "https://raw.githubusercontent.com/runwayml/models/master/gazecapture/images/demo.png",
      "organization": "CSAILVision",
      "framework": "Caffe",
      "github": "https://github.com/CSAILVision/GazeCapture",
      "paper": "http://gazecapture.csail.mit.edu/",
      "licence": "Copyright (c) 2017 - Kyle Krafka, Aditya Khosla, Petr Kellnhofer, Harini Kannan, Suchendra Bhandarkar, Wojciech Matusik, and Antonio Torralba."
    },
    "inputs": ["Image", "Video"]
  },
  {
    "containerId": "00",
    "available": false,
    "tag": "",
    "name": "Detectron",
    "specs": {
      "cpu": false,
      "gpu": true
    },
    "size": "",
    "options": {
      "image": "",
      "Tty": false,
      "Detach": true,
      "ExposedPorts": { "33000/tcp": {} },
      "HostConfig": {
        "AutoRemove": true,
        "PortBindings": {
          "33000/tcp": [{
            "HostIP": "0.0.0.0",
            "HostPort": "33000"
          }]
        }
      }
    },
    "shortDescription": "",
    "description": "",
    "developer": "",
    "company": "",
    "framework": "",
    "docker": "",
    "github": "",
    "url": "",
    "inputs": []
  },
  {
    "containerId": "00",
    "available": false,
    "tag": "",
    "name": "DeepSpeech",
    "specs": {
      "cpu": false,
      "gpu": true
    },
    "size": "",
    "options": {
      "image": "",
      "Tty": false,
      "Detach": true,
      "ExposedPorts": { "33000/tcp": {} },
      "HostConfig": {
        "AutoRemove": true,
        "PortBindings": {
          "33000/tcp": [{
            "HostIP": "0.0.0.0",
            "HostPort": "33000"
          }]
        }
      }
    },
    "shortDescription": "",
    "description": "",
    "developer": "",
    "company": "",
    "framework": "",
    "docker": "",
    "github": "",
    "url": "",
    "inputs": []
  }
]
